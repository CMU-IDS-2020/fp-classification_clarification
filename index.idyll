[meta title:"Final Project" description:"Short description of your project" /]

[Header
  fullWidth:true
  title:"A Beginners Guide To Machine Learning"
  subtitle:"A friendly, interactive guide to teach you about Classification"
  author:"Laura Howard, Christian Deverall, Nathan Jen, Juliette Wong"
  authorLink:"https://idyll-lang.org"
  date:`(new Date()).toDateString()`
  background:"#222222"
  color:"#ffffff"
/]

[var name:"introStep" value:0 /]
[Scroller currentStep: introStep]

  [Graphic className:"d3-component-container"]
    [img src:"static/images/machineLearning.png" /]
  [/Graphic]
  [Step]
    # A Brief History of Classification  

    [p className:'introSubtitle']Can computers learn from data?[/p]

    This question led to the development of machine learning.  In 1959, Arthur Samuel (a pioneer computer scientist) 
    defined machine learning as “the field of study that [b] gives computers the ability to learn without being explicitly programmed[/b]”.

    While this may sound complex, we hope to make some machine learning concepts approachable and easy to learn 
    through examples and activities in this article.

    Think of it this way – as you can learn these concepts through experimenting with examples, computers can do the same!

    To grasp how machine learning works, we need to understand [b]algorithms - the method for creating models from data[/b].  
    In this article, we will show you algorithms that perform classification tasks on a famous machine learning dataset.  
    Classification in today’s world is responsible for advancements in speech recognition, face detection, handwriting 
    recognition, and even email spam identification.
    
  [/Step]
[/Scroller]

[Scroller currentStep: caseStudyStep]
    [Graphic className:"d3-component-container"]
      [img src:"static/images/iris.png" /]
    [/Graphic]

  [Step]
    # Case Study

    ## Here is your task:

    You are Edgar Anderson, a world-renowned botanist.  Your favorite flower is the iris, and to understand this enigmatic 
    flower, you recorded measurements of 50 samples of 3 species of iris flowers, totaling 150 instances.  Your measurements 
    consist of the length and width of the sepals and petals (note that sepals are leafs that protect petals when they are budding, 
    and act as the support for the petals once bloomed).  You want to see if you can use pattern recognition to predict the iris 
    species based on your measurements.

    To complete this task, you will use three commonly used classification algorithms:  

      1. K Nearest Neighbors (KNN)   

      2. Decision Trees  

      3. Logistic Regression.

    Take a look at the data below:

  [/Step]
  [/Scroller]
    [data name:"iris" source:"iris.csv" /]
    [Table data:iris defaultPageSize:5/]


  [IdyllVegaLite data:iris spec:`{
    width: 300,
    height: 200,
    renderer: 'svg',
    mark: "circle",
    encoding: {
      x: {field: "PetalLengthCm", type: "quantitative"},
      y: {field: "SepalLengthCm", type: "quantitative"}
    }
  }` /]




[Scroller currentStep: Overfitting]
  [Graphic className:"d3-component-container"]
    [img src:"static/images/overfitting.png" /]
  [/Graphic]

    
  [Step]
    # Warning: Overfitting

    One thing to pay attention to when using algorithms is overfitting.  
    Overfitting happens when a model is too complex and starts to classify according 
    to a random error in the data over the expected relationships between variables.  
    A model is considered “overfit” when it fits your training data really well, yet performs 
    poorly on new data. One way to identify an “overfit” is to reserve a portion of your data 
    set and introduce it after you are finished creating your model to see how it performs.
  [/Step]

[/Scroller]

[Scroller currentStep: KNN]
  [Graphic className:"d3-component-container"]
    [img src:"static/images/knn.png" /]
  [/Graphic]
  [Step]
    # K Nearest Neighbors (KNN)

    The K Nearest Neighbors (KNN) algorithm classifies data based on data that is most similar.  
    You will use this algorithm to guess the iris species based on similar known data.  

    We can apply this to the iris dataset, and vary the number of neighbors (K) in our model. 
    When we do so, we see that our model outputs different accuracy levels for both the training 
    data and the test data. 
  [/Step]

  [Step]
    In this example the the right, our “test point” is the red star in the center. when we set K = 3, we 
    see that there are two points near it that are class B, and one that is class A. Since class 
    B is the majority, we label the test point as class B. However, when we set K = 6, 4 of the 
    nearest neighbors to the test point are in class A, while 2 are in class B. Thus, when K = 6, 
    we would label our test point as Class A.
  [/Step]

  [Step]
    We can apply this to the iris dataset, and vary the number of neighbors (K) in our model. 
    When we do so, we see that our model outputs different accuracy levels for both the training 
    data and the test data. 

    [img src:"static/images/knn2.png" /]
  [/Step]
  [/Scroller]

[Scroller currentStep: DecisionTrees]
  [Graphic className:"d3-component-container"]
    [img src:"static/images/dt.png" /]
  [/Graphic]
  [Step]
    # Decision Trees

    The Decision Tree algorithm splits data according to certain parameters. One can think 
    of this as having a flow-chart like structure, where each data point goes through the tree 
    and is subsequently labeled based on the attributes of the data point.  
  [/Step]
[/Scroller]

[Scroller currentStep: LogisticRegression]
  [Graphic className:"d3-component-container"]
    [img src:"static/images/lr.png" /]
  [/Graphic]
  [Step]
    # Logistic Regression  

    Logistic Regression is a classification algorithm that first finds a linear regression 
    based on the attributes of the data, and then passes that regression output to a sigmoid 
    function to convert it to a probability of whether or not the data point is of a certain class.
  [/Step]

[/Scroller]

[var name:"introStep" value:0 /]
[Scroller currentStep: introStep]
[/Scroller]
